{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Web Scraping Tutorial using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This tutorial is a reproduction of DataQuest's _Python Web Scraping Tutorial using BeautifulSoup_. The original link can be found here: https://www.dataquest.io/blog/web-scraping-tutorial-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The goal of this exercise is to scrape the National Weather Service website for last week's data in Washington, DC, store the data in a dataframe and then perform a simple analysis of the data with tools learned in Pandas. This tutorial is derived from the DataQuest tutorial found: https://www.dataquest.io/blog/web-scraping-tutorial-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the webpage that we will be scraping from to gather data on the extended forecast:\n",
    "\n",
    "https://forecast.weather.gov/MapClick.php?lat=38.8904&lon=-77.032#.W2IV8NhKiuU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep work (solutions provided until starter code begins)\n",
    "\n",
    "1. Find the Extended Forcast on the webpage\n",
    "2. Use Chrome tools to \"Inspect\" the page\n",
    "3. Look for the Extended Forecase text\n",
    "4. Find the \"outermost\" element that contains all the forecast text\n",
    "5. What kind of tag is this? --> Div tag with id \"seven-day-forecast\"\n",
    "6. What is \"Tonight\" and the following days contained in? --> div, \"tombstone-container\"\n",
    "7. Drill down into the tombstone-container and see how the elements are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using requests.get method whcih can be found here:\n",
    "\n",
    "http://docs.python-requests.org/en/master/user/quickstart/#make-a-request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request the page to download the entire page\n",
    "# It should read \"200\" for success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the page we downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BS object to help use parse the html, \"< >\" are hints to enter\n",
    "\n",
    "# Use prettify to format the html content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter code only... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the div with id \"seven-day-forcast\" and assign to \"seven_day\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inside seven_day, find one individual forecast item and assign to \"forecast_item\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract ALL the tombstones and call it \"forecaset_items\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract one-day forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract and print the first forecast item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"period\" text, call the new variable \"period\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"short-desc\" text, call the new variable \"short_desc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"temp\" text, call the new variable \"temp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print period, short_desc and temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the title attribute from the img tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all the elements from tombstone in one variable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension to to call the get_text method on each BS object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same technique to the other (3) fields \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining our data into a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to pass each list of items that we have created and stored in variables. This will include:\n",
    " - period\n",
    " - short_desc\n",
    " - temp\n",
    " - desc\n",
    " \n",
    " We will pass these as a dictionary into the DataFrame class in Pandas. Each dictionary will become a column in the DataFrame., with each list element as part of the value in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Series.str.extract method to insert a regular expression to pull out numeric temperature values\n",
    "\n",
    "# Convert to an integer\n",
    "\n",
    "#Display variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean of this week's temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows that occur only at night\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
